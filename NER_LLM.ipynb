{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "Pqelo61DGpuV",
   "metadata": {
    "id": "Pqelo61DGpuV"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import logging\n",
    "\n",
    "# Get the logger that produces the warning message\n",
    "logger = logging.getLogger('langchain_text_splitters.base')\n",
    "\n",
    "# Set the logging level to a higher level such as ERROR or CRITICAL\n",
    "logger.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606986be-fd43-4b0f-b69b-02250e57e4b0",
   "metadata": {
    "id": "606986be-fd43-4b0f-b69b-02250e57e4b0"
   },
   "source": [
    "### Install necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae9d6495-af97-405d-b4d6-63b322cb82d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ae9d6495-af97-405d-b4d6-63b322cb82d5",
    "outputId": "5dd921d2-7245-4481-e735-836179244a59",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (4.2.0)\n",
      "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.11.0)\n"
     ]
    }
   ],
   "source": [
    "#install necessray packages\n",
    "!pip install -q -U torch tensorflow transformers langchain  faiss-cpu sentence_transformers\n",
    "!pip install -q peft==0.4.0 trl==0.4.7 accelerate==0.21.0 bitsandbytes==0.41.3\n",
    "!pip install pypdf PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacdda41-708b-4af8-88a9-5056cbd08bf4",
   "metadata": {
    "id": "bacdda41-708b-4af8-88a9-5056cbd08bf4"
   },
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "505ca9a3-8c27-442e-bca6-154a65186d01",
   "metadata": {
    "id": "505ca9a3-8c27-442e-bca6-154a65186d01",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import packages\n",
    "import os\n",
    "import torch\n",
    "from transformers import (\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import AsyncChromiumLoader\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from PyPDF2 import PdfReader\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0K7BVC2Ctvnv",
   "metadata": {
    "id": "0K7BVC2Ctvnv"
   },
   "source": [
    "### 1.\tDevelop a Python script to accept NER responses as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9AZq3MXrtvKn",
   "metadata": {
    "id": "9AZq3MXrtvKn"
   },
   "outputs": [],
   "source": [
    "# This cell get NER resonse from json and accept NER resonses as input\n",
    "\n",
    "def get_NER(file_name):\n",
    "    types = ['ADRESS', 'DATE', 'EMAIL', 'MANUAL_MARKED', 'NAME',\n",
    "             'ORGANIZATION', 'METRICS']\n",
    "    # dict structrure of false positive\n",
    "    false_positives = dict()\n",
    "    false_positives['ADRESS'] = []\n",
    "    false_positives['DATE'] = []\n",
    "    false_positives['EMAIL'] = []\n",
    "    false_positives['MANUAL_MARKED'] = []\n",
    "    false_positives['NAME'] = []\n",
    "    false_positives['ORGANIZATION'] = []\n",
    "    false_positives['METRICS'] = []\n",
    "\n",
    "    #dict structure of NER\n",
    "    NER = dict()\n",
    "    NER['ADRESS'] = []\n",
    "    NER['DATE'] = []\n",
    "    NER['EMAIL'] = []\n",
    "    NER['MANUAL_MARKED'] = []\n",
    "    NER['NAME'] = []\n",
    "    NER['ORGANIZATION'] = []\n",
    "    NER['METRICS'] = []\n",
    "\n",
    "\n",
    "    # Opening JSON file\n",
    "    f = open(file_name, encoding=\"utf-8\")\n",
    "\n",
    "    # returns JSON object as\n",
    "    # a dictionary\n",
    "    data = json.load(f)\n",
    "\n",
    "    for n in range(len(data[0])):\n",
    "\n",
    "        try:\n",
    "            # number of false positives\n",
    "            false_p_n = data[0][n]['matches']['false_positives']['entity_page_mapping']\n",
    "\n",
    "            #add false positives\n",
    "            for k in range(len(false_p_n)):\n",
    "                false_positives[types[n]].extend([false_p_n[k]['text']])\n",
    "                NER[types[n]].extend([false_p_n[k]['text']])\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            # number of false negative\n",
    "            false_n_n = data[0][n]['matches']['false_negative']['entity_page_mapping']\n",
    "\n",
    "            # add false negative\n",
    "            for k in range(len(false_n_n)):\n",
    "                NER[types[n]].extend([false_n_n[k]['text']])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            # number of True positve\n",
    "            true_p_n = data[0][n]['matches']['true_positive']['entity_page_mapping']\n",
    "\n",
    "            # add false negative\n",
    "            for k in range(len(true_p_n)):\n",
    "                NER[types[n]].extend([true_p_n[k]['text']])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return NER, false_positives\n",
    "\n",
    "NER, false_positives = get_NER('ner1.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lpQO-PAQkCHQ",
   "metadata": {
    "id": "lpQO-PAQkCHQ"
   },
   "source": [
    "LLM analyze the context of NER entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DmIUCrFBuYHe",
   "metadata": {
    "id": "DmIUCrFBuYHe"
   },
   "source": [
    "### 2.\tIntegrate a Language Model (LLM) into the program to analyze the context of entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cvWBplnpucp-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "dd5590aca14544cf87714e29a6192b08",
      "bc9d68e385a04f15a9f46a1838f08791",
      "34340720076340b1bb9e1850335144fd",
      "9dc943be90ee4bedb039e0d9f73133b3",
      "e0da5c16b5d841098260bf3c4649a1cf",
      "091d85e715b0482faa47afe54c77feac",
      "07c3e1cf35c8438ba135571c816ad644",
      "c653a21cb0944ab886436c90f3ed837c",
      "3ae8baff5d2042ce87407602e6372883",
      "b1c9bce595f34b6381d097ed246a3bfb",
      "1e0b9740defa4b6980ab01facf2fd184"
     ]
    },
    "id": "cvWBplnpucp-",
    "outputId": "5f6ac0de-0591-4743-d09e-29b1f93018ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd5590aca14544cf87714e29a6192b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Tokenizer is defined here. Tokenizer model is loaded from pretrained Mistral 7B model\n",
    "#LLM model is loaed from pretrained Mistral 7B model\n",
    "\n",
    "# tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "                                          trust_remote_code=True,\n",
    "                                          use_auth_token='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')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "# define quantization config file\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type= \"nf4\", #fp4 or nf4,\n",
    "    bnb_4bit_compute_dtype=  \"float16\",\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")\n",
    "\n",
    "# Load pre-trained model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    quantization_config=bnb_config,\n",
    "    use_auth_token='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'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "gqKFpxBhvD_W",
   "metadata": {
    "id": "gqKFpxBhvD_W"
   },
   "outputs": [],
   "source": [
    "# Define text pipeline\n",
    "# This pipline defines processes of LLM for NER analysis\n",
    "text_pipeline = pipeline(\n",
    "    temperature=0.2,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    model=model,\n",
    "    repetition_penalty=1.12,\n",
    "    return_full_text=True,\n",
    "    max_new_tokens=290,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "BW3NSskwvJ72",
   "metadata": {
    "id": "BW3NSskwvJ72"
   },
   "outputs": [],
   "source": [
    "# define hugging face pipeline\n",
    "# mistal model is run through the HuggingFacePipeline class\n",
    "mistral_llm = HuggingFacePipeline(pipeline=text_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eDPy98Dvzn1m",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eDPy98Dvzn1m",
    "outputId": "7f9c98bd-f81e-42df-f446-526588a79b90"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# This cell defines language model for NER responses\n",
    "\n",
    "# define prompt template\n",
    "prompt_template = \"\"\"\n",
    "### [INST] Instruction: Analyse NER data. NER data are given in the input data.\n",
    " NER data is dictionary\n",
    "\n",
    "###\n",
    "INPUT:\n",
    "{input} [/INST]\n",
    " \"\"\"\n",
    "\n",
    "# Create prompt from prompt template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"input\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "# Create llm chain\n",
    "llm_chain = LLMChain(llm=mistral_llm, prompt=prompt)\n",
    "\n",
    "# Build RAG chain\n",
    "rag_chain = (\n",
    " {\"input\": RunnablePassthrough()}\n",
    "    | llm_chain\n",
    ")\n",
    "\n",
    "# define function for quesion and answer\n",
    "def analyze_NER(input):\n",
    "  result = rag_chain.invoke(input)\n",
    "  answer = result['text']\n",
    "  print('Answer:')\n",
    "  print(answer.split('[/INST]')[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7iCYt-hgPKXL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7iCYt-hgPKXL",
    "outputId": "29df6691-a426-4761-ca03-784aae5baf33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "\n",
      "  Based on the given NER (Named Entity Recognition) data, we have the following key-value pairs:\n",
      "\n",
      "  1. 'ADRESS': []\n",
      "     This key represents a location or an address. The current value is an empty list.\n",
      "\n",
      "  2. 'DATE': ['1 July 2009', '1 March 2020', '24-02-2020']\n",
      "      This key represents dates. The current value is a list containing three date strings.\n",
      "\n",
      "  3. 'EMAIL': []\n",
      "       This key represents email addresses. The current value is an empty list.\n",
      "\n",
      "  4. 'MANUAL_MARKED': []\n",
      "        This key may represent manually marked entities. However, the current value is an empty list and it's not clear what these entities might be without additional context.\n",
      "\n",
      "  5. 'NAME': ['Sergey Balk']\n",
      "         This key represents names of people or organizations. The current value is a list containing one name string: \"Sergey Balk\".\n",
      "\n",
      "  6. 'ORGANIZATION': ['Assistance', 'Chi utive Officer Globality S.A', 'Czech Republic Company', 'Data Controller', 'Data Processor', 'Ergo', 'Ergo Group', 'Ergo Group AG', 'Euro-Center',\n"
     ]
    }
   ],
   "source": [
    "analyze_NER(NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NUP4uPWi1ktN",
   "metadata": {
    "id": "NUP4uPWi1ktN"
   },
   "source": [
    "### 3.\tImplement a filtering mechanism to identify and remove false positives from the NER responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "nnLUOIOL12lu",
   "metadata": {
    "id": "nnLUOIOL12lu"
   },
   "outputs": [],
   "source": [
    "# This cell defines language model for NER responses\n",
    "# define prompt template to identify and remove false poitives from the NER reponse\n",
    "prompt_template = \"\"\"\n",
    "### [INST] Instruction:  please identify and remove false positives from the NER data.\n",
    " NER data is dictionary\n",
    " Please output the filtered NER data and false positive data\n",
    "\n",
    "###\n",
    "INPUT:\n",
    "{input} [/INST]\n",
    "\"\"\"\n",
    "# Create prompt from prompt template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"input\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "# Create llm chain\n",
    "llm_chain = LLMChain(llm=mistral_llm, prompt=prompt)\n",
    "\n",
    "# Build RAG chain\n",
    "rag_chain = (\n",
    " {\"input\": RunnablePassthrough()}\n",
    "    | llm_chain\n",
    ")\n",
    "\n",
    "# define function for quesion and answer\n",
    "def remove_false_positive_NER(input):\n",
    "  result = rag_chain.invoke(input)\n",
    "  answer = result['text']\n",
    "  print('Answer:')\n",
    "  print(answer.split('[/INST]')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2SQgyh7OTjlE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2SQgyh7OTjlE",
    "outputId": "d6a3e11f-9be3-4273-af42-a0a2ef15ed37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "\n",
      "  OUTPUT:\n",
      "  {'ADRESS': ['Europe South New Bangkok, Beijing, Sydney, Africa'], 'DATE': ['1 January 2012', '11 September 2009'], 'EMAIL': [], 'MANUAL_MARKED': [], 'NAME': ['Steichen', 'Velde'], 'ORGANIZATION': ['Assurances', 'Azur', 'Azur Euro Center', 'Center', 'Commissariat aux Assurances', 'Complete Bank', 'Coo fpp-cind', 'Dkv Globality', 'Dkv Globality S.A', 'Dkv Globality S.A. (\"Dkv Globality\"', \"Dkv Globality's\", 'Euro', 'Euro Center', 'Euro Center Holding', 'Euro Center Holding A/S Frederiksberg Allé', 'Euro Center Holding a/S (\"Euro Center\"', \"Euro Center's\", 'Euro Centers', 'Euro-Center', 'Euro-Center Holding', 'Glbality', 'Munich Re Group', 'notifying Party'], 'METRICS': []}\n",
      "  \n",
      " False Positives: ['Azur Euro Center Holding', 'Euro Center Holding A/S (\"Euro Center\"', \"Euro Center'\n"
     ]
    }
   ],
   "source": [
    "NER, _  = get_NER('ner2.json')\n",
    "remove_false_positive_NER(NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mrQiQ8v9ktOA",
   "metadata": {
    "id": "mrQiQ8v9ktOA"
   },
   "source": [
    "False positives are identified and removed from the NER responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Yexa3Vq813f-",
   "metadata": {
    "id": "Yexa3Vq813f-"
   },
   "source": [
    "### 4.\tOptimize the program for efficiency and scalability, considering large volumes of NER data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9BoqKQIGcqIY",
   "metadata": {
    "id": "9BoqKQIGcqIY"
   },
   "outputs": [],
   "source": [
    "# Define text pipeline\n",
    "# This pipline defines processes of LLM for NER analysis\n",
    "# parameters for pipline are set as follows\n",
    "# temperature=0.18: This parameter controls the randomness of the generated text. A lower temperature value results in more deterministic output,\n",
    "# while a higher value allows for more randomness.\n",
    "# repetition_penalty=1.2: This parameter controls the likelihood of the model repeating the same words or phrases in the generated text.\n",
    "# A higher repetition penalty discourages repetitive output.\n",
    "# max_new_tokens=310: This parameter sets the maximum number of new tokens that can be generated by the model.\n",
    "# It limits the length of the generated text to prevent excessively long outputs.\n",
    "\n",
    "text_pipeline2 = pipeline(\n",
    "    temperature=0.18,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    model=model,\n",
    "    repetition_penalty=1.2,\n",
    "    return_full_text=True,\n",
    "    max_new_tokens=310,\n",
    ")\n",
    "# define hugging face pipeline\n",
    "# mistal model is run through the HuggingFacePipeline class\n",
    "mistral_llm2 = HuggingFacePipeline(pipeline=text_pipeline2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "u7-KXft1cccI",
   "metadata": {
    "id": "u7-KXft1cccI"
   },
   "outputs": [],
   "source": [
    "# This cell defines language model for NER responses\n",
    "\n",
    "# define prompt template\n",
    "prompt_template = \"\"\"\n",
    "### [INST] Instruction:  please identify and remove false positives from the NER data.\n",
    " NER data is dictionary\n",
    " Please output the filtered NER\n",
    " please output false positive data in unrepeat format\n",
    "\n",
    "\n",
    "###\n",
    "INPUT:\n",
    "{input} [/INST]\n",
    " \"\"\"\n",
    "\n",
    "# Create prompt from prompt template\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"input\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "# Create llm chain\n",
    "llm_chain = LLMChain(llm=mistral_llm2, prompt=prompt)\n",
    "\n",
    "# Build RAG chain\n",
    "rag_chain = (\n",
    " {\"input\": RunnablePassthrough()}\n",
    "    | llm_chain\n",
    ")\n",
    "\n",
    "# define function for quesion and answer\n",
    "def remove_false_positive_NER2(input):\n",
    "  result = rag_chain.invoke(input)\n",
    "  answer = result['text']\n",
    "  print('Answer:')\n",
    "  print(answer.split('[/INST]')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "vhCYZQhN17z9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vhCYZQhN17z9",
    "outputId": "86a773ee-3771-4228-f471-a6f5218dcdee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "\n",
      "  Based on my analysis, here are the false positives that need to be removed from the given NER data:\n",
      "\n",
      "False Positives:\n",
      "['City: D-20010 Hamburg', 'Country: Germany']\n",
      "\n",
      "Filtered NER Data:\n",
      "{'ADRESS': [...], 'DATE': [...], 'EMAIL': [], 'MANUAL_MARKED': [...], 'NAME': [...], 'ORGANIZATION': ['Danske Bank Hamburg Corporate Banking', 'Danske', 'Danske Bank Hamburg', 'Danske', 'Danske Bank Hamburg', 'Danske', 'Danske Bank Hamburg', 'Danske', 'Danske Bank Hamburg', 'Danske', 'Danske Bank Hamburg', 'Danske', 'Danske Bank Hamburg', 'Danske', 'Danske Bank Hamburg', 'Danske', 'Danske Bank Hamburg', 'Danske', 'Danske Bank Hamburg', 'Danske', 'Danske Bank Hamburg', 'Danske', 'Danske Bank Hamburg', 'Danske', 'Danske Bank Hamburg', 'Danske', 'Danske Bank Hamburg', 'Danske', 'Danske Bank Hamburg', 'Danske', 'Danske Bank Hamburg', 'Danske', 'Danske Bank Hamburg', 'Danske', 'Danske Bank Hamburg', '\n"
     ]
    }
   ],
   "source": [
    "NER, _  = get_NER('ner3.json')\n",
    "remove_false_positive_NER2(NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m32n44K_k_sJ",
   "metadata": {
    "id": "m32n44K_k_sJ"
   },
   "source": [
    "False positives are identified and removed from the NER responses"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "common-gpu.m114",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-gpu:m114"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07c3e1cf35c8438ba135571c816ad644": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "091d85e715b0482faa47afe54c77feac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e0b9740defa4b6980ab01facf2fd184": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "34340720076340b1bb9e1850335144fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c653a21cb0944ab886436c90f3ed837c",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3ae8baff5d2042ce87407602e6372883",
      "value": 3
     }
    },
    "3ae8baff5d2042ce87407602e6372883": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9dc943be90ee4bedb039e0d9f73133b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b1c9bce595f34b6381d097ed246a3bfb",
      "placeholder": "​",
      "style": "IPY_MODEL_1e0b9740defa4b6980ab01facf2fd184",
      "value": " 3/3 [01:09&lt;00:00, 22.19s/it]"
     }
    },
    "b1c9bce595f34b6381d097ed246a3bfb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc9d68e385a04f15a9f46a1838f08791": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_091d85e715b0482faa47afe54c77feac",
      "placeholder": "​",
      "style": "IPY_MODEL_07c3e1cf35c8438ba135571c816ad644",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "c653a21cb0944ab886436c90f3ed837c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd5590aca14544cf87714e29a6192b08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bc9d68e385a04f15a9f46a1838f08791",
       "IPY_MODEL_34340720076340b1bb9e1850335144fd",
       "IPY_MODEL_9dc943be90ee4bedb039e0d9f73133b3"
      ],
      "layout": "IPY_MODEL_e0da5c16b5d841098260bf3c4649a1cf"
     }
    },
    "e0da5c16b5d841098260bf3c4649a1cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
